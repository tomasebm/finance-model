"""
DAILY MERVAL SIGNAL ‚Äî PRODUCTION SCRIPT (FINAL v2.1)
Runs once per day after market close (~18:00 ART).

Fixes:
- Correct BigQuery table_id formatting + error logs
- Robust yfinance parsing (MultiIndex, adj close fallback)
- VIX jump division protection
- Enforce BASE_SAFE_CORE floor in allocation
- Cloud Logging for shock detection
- Testing mode with FORCE_SHOCK_ALERT
"""

import warnings
warnings.filterwarnings("ignore")

import os
import traceback
from datetime import datetime, timedelta, timezone

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

from google.cloud import bigquery
from google.cloud import logging as cloud_logging

# ===============================
# CONFIG
# ===============================
START_DATE = os.environ.get("START_DATE", "2015-01-01")

# Portfolio: SPY = safe core, GGAL = tactical risk
BASE_SAFE_CORE = float(os.environ.get("BASE_SAFE_CORE", "0.50"))
MAX_RISK_ALLOCATION = float(os.environ.get("MAX_RISK_ALLOCATION", "0.50"))

# Shock rules
SHOCK_DAILY_RET = float(os.environ.get("SHOCK_DAILY_RET", "-0.055"))
VIX_JUMP_2D = float(os.environ.get("VIX_JUMP_2D", "0.22"))

# Threshold shaping
BASE_THR = float(os.environ.get("BASE_THR", "0.60"))
ALPHA = float(os.environ.get("ALPHA", "0.15"))
THR_MIN = float(os.environ.get("THR_MIN", "0.20"))
THR_MAX = float(os.environ.get("THR_MAX", "0.80"))

# Model params
N_ESTIMATORS = int(os.environ.get("N_ESTIMATORS", "300"))
MAX_DEPTH = int(os.environ.get("MAX_DEPTH", "5"))
MIN_SAMPLES_LEAF = int(os.environ.get("MIN_SAMPLES_LEAF", "30"))
RANDOM_STATE = int(os.environ.get("RANDOM_STATE", "42"))

# BigQuery
PROJECT_ID = os.environ.get("PROJECT_ID", "merval-482121")
DATASET = os.environ.get("BQ_DATASET", "merval_signals")
TABLE = os.environ.get("BQ_TABLE", "daily_signal")

# Output file
CSV_PATH = os.environ.get("CSV_PATH", "daily_signal.csv")

# Testing mode
FORCE_SHOCK_ALERT = os.environ.get("FORCE_SHOCK_ALERT", "false").lower() == "true"


# ===============================
# HELPERS
# ===============================
def yf_fetch(ticker: str) -> pd.DataFrame:
    """
    Fetches data from Yahoo Finance with robust MultiIndex handling.
    """
    end_dt = (datetime.now(timezone.utc) + timedelta(days=1)).strftime("%Y-%m-%d")
    df = yf.download(ticker, start=START_DATE, end=end_dt, progress=False)

    if df is None or df.empty:
        raise RuntimeError(f"Failed to load data for {ticker}")

    # Robust flattening of MultiIndex columns (yfinance v0.2+)
    if isinstance(df.columns, pd.MultiIndex):
        try:
            df.columns = df.columns.get_level_values(0)
        except Exception:
            df.columns = [str(c) for c in df.columns]

    # Normalize column names
    df.columns = [str(c).lower().strip() for c in df.columns]

    # Handle 'adj close' vs 'close'
    if "close" not in df.columns and "adj close" in df.columns:
        df["close"] = df["adj close"]

    if "close" not in df.columns:
        raise RuntimeError(f"{ticker} missing 'close' column. Cols found: {list(df.columns)}")

    df["close"] = pd.to_numeric(df["close"], errors="coerce").ffill()
    df = df.dropna(subset=["close"])
    return df


def log_shock_alert(date_str: str, latest_ret: float, vix_jump: float, forced: bool = False) -> None:
    """
    Logs shock detection to Cloud Logging with ERROR severity.
    This triggers email alerts configured in Cloud Console.
    """
    try:
        client = cloud_logging.Client(project=PROJECT_ID)
        logger = client.logger("merval-shock-detector")
        
        message = "üö® MERVAL SHOCK DETECTED"
        if forced:
            message = "üß™ TEST ALERT - FORCED SHOCK"
        
        logger.log_struct({
            "message": message,
            "date": date_str,
            "merval_daily_return": f"{latest_ret:.2%}",
            "vix_jump_2d": f"{vix_jump:.2%}",
            "shock_threshold_ret": f"{SHOCK_DAILY_RET:.2%}",
            "shock_threshold_vix": f"{VIX_JUMP_2D:.2%}",
            "action": "Portfolio moved to 100% SPY (safe core)",
            "forced_test": forced
        }, severity="ERROR")
        
        print(f"‚úÖ Shock alert logged to Cloud Logging")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to log shock alert: {e}")
        traceback.print_exc()


def save_to_bigquery(date: str,
                     signal_strength: float,
                     exp_spy: float,
                     exp_ggal: float,
                     shock_bool: int) -> None:
    """
    Appends one row to BigQuery table.
    """
    client = None
    table_id = f"{PROJECT_ID}.{DATASET}.{TABLE}"

    try:
        client = bigquery.Client(project=PROJECT_ID)

        rows_to_insert = [{
            "date": date,
            "signal_strength": float(signal_strength),
            "exposure_spy": float(exp_spy),
            "exposure_ggal": float(exp_ggal),
            "shock_nextday": int(shock_bool),
            "created_at": datetime.now(timezone.utc).isoformat()
        }]

        errors = client.insert_rows_json(table_id, rows_to_insert)
        if errors:
            print(f"BigQuery insert errors: {errors}")
        else:
            print(f"Saved to BigQuery: {table_id}")

    except Exception:
        print(f"BigQuery save failed for {table_id}")
        traceback.print_exc()


# ===============================
# MAIN
# ===============================
def main() -> None:
    print(f"Starting job at {datetime.now(timezone.utc).isoformat()}")
    
    if FORCE_SHOCK_ALERT:
        print("‚ö†Ô∏è  TESTING MODE: FORCE_SHOCK_ALERT is enabled")

    # Basic sanity: ensure portfolio constraints are consistent
    if BASE_SAFE_CORE < 0.0 or BASE_SAFE_CORE > 1.0:
        raise ValueError(f"BASE_SAFE_CORE must be in [0,1], got {BASE_SAFE_CORE}")
    if MAX_RISK_ALLOCATION < 0.0 or MAX_RISK_ALLOCATION > 1.0:
        raise ValueError(f"MAX_RISK_ALLOCATION must be in [0,1], got {MAX_RISK_ALLOCATION}")
    if BASE_SAFE_CORE + MAX_RISK_ALLOCATION > 1.0000001:
        raise ValueError(
            f"Invalid constraints: BASE_SAFE_CORE({BASE_SAFE_CORE}) + MAX_RISK_ALLOCATION({MAX_RISK_ALLOCATION}) > 1.0"
        )

    # 1. FETCH DATA
    merval = yf_fetch("^MERV")
    vix = yf_fetch("^VIX")
    argt = yf_fetch("ARGT")

    # 2. ALIGN TO MERVAL CALENDAR
    idx = merval.index
    df = pd.DataFrame(index=idx)
    df["merval_close"] = merval["close"]
    df["merval_ret"] = df["merval_close"].pct_change()

    df["vix"] = vix["close"].reindex(idx).ffill()
    df["argt"] = argt["close"].reindex(idx).ffill()

    # 3. FEATURE ENGINEERING
    df["vix_reg"] = pd.cut(df["vix"], [0, 15, 20, 30, 40, 999],
                           labels=[0, 1, 2, 3, 4]).astype(float)
    df["argt_stress"] = -np.log(df["argt"]).diff()
    df["ret_5d"] = df["merval_ret"].rolling(5).sum()
    df["vol_10d"] = df["merval_ret"].rolling(10).std()

    df = df.dropna()

    if len(df) < 300:
        raise RuntimeError(f"Not enough data: {len(df)} rows")

    feature_cols = ["vix_reg", "argt_stress", "ret_5d", "vol_10d"]

    # 4. SHOCK DETECTION (TODAY)
    latest_ret = float(df["merval_ret"].iloc[-1])
    latest_vix = float(df["vix"].iloc[-1])

    if len(df) >= 3:
        prev2_vix = float(df["vix"].iloc[-3])
    else:
        prev2_vix = float(df["vix"].iloc[0])

    vix_jump = 0.0
    if prev2_vix > 0:
        vix_jump = latest_vix / prev2_vix - 1.0

    is_shock = FORCE_SHOCK_ALERT or (latest_ret <= SHOCK_DAILY_RET) or (vix_jump >= VIX_JUMP_2D)

    # 5. TRAIN MODEL (Daily Walk-Forward)
    label = (df["merval_ret"].shift(-1) < -0.02).astype(int)

    train_df = df.iloc[:-1]
    y_train = label.iloc[:-1]
    X_train_raw = train_df[feature_cols]

    sc = StandardScaler()
    X_train = sc.fit_transform(X_train_raw)

    clf = RandomForestClassifier(
        n_estimators=N_ESTIMATORS,
        max_depth=MAX_DEPTH,
        min_samples_leaf=MIN_SAMPLES_LEAF,
        class_weight="balanced",
        random_state=RANDOM_STATE,
        n_jobs=1,
    )
    clf.fit(X_train, y_train)

    # 6. PREDICT TOMORROW
    latest_row = df.iloc[-1:]
    latest_X = sc.transform(latest_row[feature_cols])
    prob_crash = float(clf.predict_proba(latest_X)[0, 1])

    # 7. THRESHOLD + SIGNAL
    vix_norm = float(np.clip(float(latest_row["vix_reg"].iloc[0]) / 4.0, 0.0, 1.0))
    thr = float(np.clip(BASE_THR - ALPHA * vix_norm, THR_MIN, THR_MAX))
    signal_strength = float(np.clip(1.0 - prob_crash / max(thr, 1e-6), 0.0, 1.0))

    # 8. PORTFOLIO ALLOCATION (ENFORCE BASE_SAFE_CORE)
    risk_alloc = signal_strength * MAX_RISK_ALLOCATION

    if is_shock:
        date_str = df.index[-1].strftime("%Y-%m-%d")
        print("=" * 60)
        if FORCE_SHOCK_ALERT:
            print("üß™ TEST ALERT - FORCED SHOCK üß™")
        else:
            print("üö® SHOCK DETECTED üö®")
        print("=" * 60)
        print(f"Date: {date_str}")
        print(f"MERVAL Return: {latest_ret:.2%} (threshold: {SHOCK_DAILY_RET:.2%})")
        print(f"VIX Jump (2d): {vix_jump:.2%} (threshold: {VIX_JUMP_2D:.2%})")
        print(f"Action: Moving to 100% SPY (safe core)")
        print("=" * 60)
        
        # Log to Cloud Logging (triggers email alert)
        log_shock_alert(date_str, latest_ret, vix_jump, forced=FORCE_SHOCK_ALERT)
        
        risk_alloc = 0.0

    exposure_ggal = float(np.clip(risk_alloc, 0.0, MAX_RISK_ALLOCATION))
    exposure_spy = max(BASE_SAFE_CORE, 1.0 - exposure_ggal)
    exposure_spy = float(np.clip(exposure_spy, 0.0, 1.0))
    exposure_ggal = float(np.clip(1.0 - exposure_spy, 0.0, MAX_RISK_ALLOCATION))

    # 9. OUTPUT & SAVE
    date_str = df.index[-1].strftime("%Y-%m-%d")
    output = {
        "date": date_str,
        "signal_strength": round(signal_strength, 3),
        "exposure_spy": round(exposure_spy, 2),
        "exposure_ggal": round(exposure_ggal, 2),
        "shock_nextday": int(is_shock),
    }

    print("=" * 30)
    print("DAILY SIGNAL")
    print("=" * 30)
    print(output)

    # Save CSV (append)
    out_df = pd.DataFrame([output])
    out_df.to_csv(CSV_PATH, mode="a", header=not os.path.exists(CSV_PATH), index=False)

    # Save BigQuery
    save_to_bigquery(
        date=output["date"],
        signal_strength=output["signal_strength"],
        exp_spy=output["exposure_spy"],
        exp_ggal=output["exposure_ggal"],
        shock_bool=output["shock_nextday"],
    )

    print("Script completed successfully.")


if __name__ == "__main__":
    main()